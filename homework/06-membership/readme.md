# Group Membership

В этой задаче вам предстоит реализовать распределенный сервис для отслеживания состава группы.

Пусть имеется распределенная система, состоящая из _N_ узлов, на каждом из которых запущен процесс. У каждого процесса есть уникальный идентификатор _id_. Будем говорить, что все работающие в некоторый момент процессы образуют _группу_, то есть являются ее участниками. В ходе работы системы процессы могут запускаться или останавливаться, тем самым вступая в группу и покидая её. Таким образом, состав участников группы может изменяться со временем. Сервис, который вам надо реализовать, должен позволять процессам узнавать текущий состав группы, а также выполнять вход и выход из группы.

Помимо явного выхода из группы (например, при штатной остановке администратором), процессы могут покидать группу из-за отказов. В нашей системе возможны следующие виды отказов:
- _Падение процесса или всего узла_. При таком отказе процесс прекращает свое выполнение, теряя имевшееся у него состояние. Позднее процесс может быть перезапущен (с тем же _id_ и чистым состоянием) и заново подключен к группе. Работающий процесс будем называть _живым_.
- _Потеря сообщений сетью_ между некоторыми парами узлов, в обоих или только в одном направлении. В результате таких отказов живые процессы могут оказаться полностью или частично изолированы от других процессов. Отказы сети могут носить временный характер, после чего связь восстанавливается.

Ваша реализация должна обнаруживать описанные выше отказы и обрабатывать их. Для этого вам потребуется реализовать _детектор отказов_. Ваш детектор должен обладать свойством _полноты_ - если процесс стал недоступным из-за отказа, то в конечном счете все участники группы признают его отказавшим. Также постарайтесь найти хороший баланс между скоростью обнаружения отказов, точностью детектора и сопутствующими накладными расходами.

Упавшие или недоступные ни с одного из остальных участников группы процессы должны автоматически исключаться из состава группы. Таким образом, в состав группы должны входить только живые процессы, способные общаться по сети (в обе стороны) с хотя бы одним другим участником группы. Если упавший процесс позднее перезапускается, то он заново выполняет вход в группу под тем же _id_, после чего остальные процессы должны вернуть его в свой список участников. Если недоступный из-за отказа сети процесс позднее становится доступным, то другие участники должны обнаруживать это и аналогично возвращать процесс в свой список. 

Не требуется обеспечивать _строгую согласованность_ списков участников группы между процессами. Иными словами, допустимо, если в некоторый момент времени списки на разных процессах отличаются (например, отказавший процесс может кое-где еще выдаваться как участник группы). Главное чтобы через некоторое время после отказа или его устранения, а также входа/выхода участника, состав группы стабилизировался и стал одинаковым на всех её текущих участниках. Это называется _согласованностью в конечном счёте_.

Из-за сетевых отказов система может распасться на несколько изолированных подгрупп. Такая ситуация называется _разделением сети_. Простейшим частным случаем разделения является отключение от сети одного узла. Разделение может быть асимметричным, когда связь между частями системы отсутствует только в одну сторону. Ваша реализация должна уметь работать в условиях разделения сети, позволяя каждому живому процессу отлеживать состав участников в его подгруппе. Например, если процесс оказался отключен от сети, то он будет видеть в участниках группы только себя, а остальные процессы будут видеть в группе всех кроме него. Когда сеть восстанавливается, то в конечном счёте все живые процессы должны увидеть всех в участниках группы.

Чтобы получить максимальный балл, требуется также обеспечить хорошую масштабируемость полученного решения. А именно, при увеличении числа узлов в _X_ раз накладные расходы (сетевой трафик и число передаваемых сообщений) должны увеличиваться не более чем в _2X_ раз.  В тестах не учитываются расходы на первоначальную сборку группы, только расходы на её поддержание в ситуации без отказов и с ними. Кроме того, нагрузка на процессы (в плане числа обрабатываемых сообщений) должна распределяться равномерно - отношение max/min нагрузки по всем процессам не должно превышать 5.

Если вам плохо понятны некоторые требования, изучите соответствующие тесты - это часть условия задачи.

## Реализация

Для реализации и тестирования решения используется учебный фреймворк dslab-mp (см. материалы первого семинара). В папке задачи размещена заготовка для решения [solution.py](solution.py). Вам надо доработать реализацию процесса в классе `GroupMember` так, чтобы проходили все тесты.

При инициализации процессу передается его уникальный _id_. Процесс должен поддерживать обработку следующих локальных сообщений:
- _JOIN_ - команда присоединиться к группе. В результате обработки этой команды процесс должен стать участником группы. В поле `seed` передается идентификатор одного из живых участников группы. Если в `seed` находится идентификатор самого процесса, то он должен создать новую пустую группу и добавить в неё себя. Ответ на это сообщение не нужен.
- _LEAVE_ - команда покинуть группу. В результате обработки этой команды процесс должен перестать быть участником группы. Ответ на это сообщение не нужен.
- _GET_MEMBERS_ - запрос списка участников группы. В ответ на запрос процесс должен отправить локальное сообщение _MEMBERS_ со списком идентификаторов процессов, входящих сейчас в группу (см. заготовку). **Важно!** Данный запрос должен обрабатываться исключительно локально, без взаимодействия с другими процессами. При поступлении запроса надо сразу выдать ответ с хранимым локально списком. На соблюдение этой семантики есть отдельный тест.

Для взаимодействия между процессами вы можете использовать любые собственные типы сообщений.

**Важно!** Для измерения прошедшего времени в коде процесса используйте метод `ctx.time()`, возвращающий локальное время "внутри симуляции". Использовать обычные способы, например `time.time()`, некорректно, так как скорость течения времени в симуляции отличается от реального времени. Также не стоит опираться на синхронизацию часов в системе - у каждого узла свои локальные часы, и показания `ctx.time()` у разных процессов могут расходиться.

В коде процесса можно использовать генератор случайных чисел из `random`, но не следует его явно инициализировать с помощью `random.seed()`. Это уже делается в тестах на основе переданного seed, а дополнительная инициализация может нарушить воспроизводимость результатов.

## Тестирование

Перед запуском тестов убедитесь, что на вашей машине [установлен Rust](https://www.rust-lang.org/tools/install). 

Тесты находятся в папке `tests`. Для запуска тестов перейдите в эту папку и выполните команду: `cargo run --release`. Запустить только один из тестов можно с помощью опции `-t` (например, `cargo run --release -- -t "PROCESS CRASH"`). По умолчанию вывод тестов не содержит трассы (последовательности событий во время выполнения каждого из тестов), а только финальную сводку. Включить вывод трасс можно с помощью флага `-d`. Все доступные опции можно посмотреть с помощью `cargo run --release -- --help`. Часть из них уже должна быть вам знакома по прошлым задачам. Число тестов `CHAOS MONKEY` в GitLab CI увеличено до 1000: `cargo run --release --m 1000`.

Если тест MODEL CHECKING выполняется очень долго, то вы можете временно отключить его с помощью флага `--disable_mc_tests`, чтобы было проще проверять решение на других тестах. Однако учтите, что если этот тест упадет с ошибкой, то базовый функционал без обработки отказов засчитан не будет. Исключением является случай, когда данный тест не проходит из-за превышения лимита времени выполнения (2 минуты). Это значит, что ваша реализация создает слишком много сообщений или таймеров, скорее всего избыточных. Такая ошибка не помешает пройти группу с базовым функционалом, но с ней нельзя будет получить полный балл за задачу. Решения с такой ошибкой также редко проходят тесты на масштабируемость. В этом случае рекомендуется доработать решение, чтобы избавиться от избыточности. По опыту хорошие решения укладываются на этом тесте в несколько десятков секунд.

Если вы найдете ошибки или требования из условий, которые не покрывают наши тесты, то вы можете получить за это бонусы. Для этого надо включить в отчёт описание ситуации, которую не ловят тесты, добавив при необходимости пример решения с ошибкой. За это полагается 1 балл. Если вы также реализуете тесты, которые ловят найденную проблему, или хотя бы опишите их логику, то получите еще 1 балл. Готовые тесты оформляйте как pull request в репозиторий курса.

## Оценивание

Эта задача учитывается как 1.5 обычных, то есть максимум можно набрать **15 баллов**.

Компоненты задачи и их вклад в оценку:
- Отчёт с описанием вашего решения в файле `solution.md` - обязательно, без него проверка производиться не будет.
- Базовый функционал без обработки отказов (тесты SIMPLE, GET MEMBERS SEMANTICS, RANDOM SEED, PROCESS JOIN/LEAVE и MODEL CHECKING) - 4 балла.
  - Допускается что тест MODEL CHECKING не проходит по лимиту времени
- Обработка отказов узлов (три теста с "PROCESS CRASH" в названии) - 3 балла.
- Обработка отказов сети (остальные тесты кроме "SCALABILITY...") - 3 балла.
- Масштабируемость при росте числа узлов (два теста "SCALABILITY...") - 4 балла.
- Тест MODEL CHECKING не падает по лимиту времени - 1 балл.

## Сдача

Следуйте стандартному [порядку сдачи заданий](../readme.md).
